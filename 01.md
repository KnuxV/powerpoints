# Advanced programming with Python
#### M2 DS2E
[Kévin Michoud](kmichoud@unistra.fr) | Sept - Oct 2024
---
## Détails
- 25 heures (10h avec moi | 15h avec Pierre Pelletier)
- Beaucoup de pratique, peu de théorie
- Vous travaillez en autonomie
  <hr>
- Projet noté autour des données
- Groupes de 3
- Présentation lors du dernier cours

---
# À propos de moi
## Kévin Michoud
1. 35 ans, avec un bébé de 6 mois.
2. 3<sup>ème</sup> année de doctorat en économie avec Stefano Bianchini
3. Parcours en langues et programmation :
   1. Licence en anglais
   2. Master en Traitement Automatique des Langues (TAL = Linguistique + Programmation)

---
<div class="small-text">

#### Thèse : Relations entre les Technologies Numériques Avancées et le Développement Durable
- Étude bibliométrique (Étude des publications liées aux TNA et aux ODD)
- Analyse de Sentiment Basée sur <u>les Aspects</u> : à utiliser comme un proxy d'impact
- Processus
    1. Collecte de données : plusieurs Go de données sous forme de fichiers texte
    2. Nettoyage + Transformation en un grand tableau (1 ligne = 1 publication) et de nombreuses colonnes de métadonnées
    3. Application de l'IA (analyse de sentiment) au texte
</div>

---
#### Petit mot sur l'IA / ChatGPT
- 
- Comment enseigner l'introduction à la programmation alors que l'IA générative a trivialisé les tâches de codage basique?
<br><br>
- Comment évaluer les d'introduction à la programmation ?

---
<div class="small-text">
  
#### Petit mot sur l'IA / ChatGPT
1. **Utilisez des outils d'IA** : Nous attendons de vous que vous utilisiez l'IA générative (par exemple, ChatGPT).  
  - Saisie plus rapide
  - Connaît la syntaxe
  - Connaît plus de bibliothèques

2. **<u>MAIS</u> Comprenez ce que vous faites** : Ne vous contentez pas de copier—assurez-vous de :
  - **Demander** : Interrogez votre enseignant, ChatGPT, ou Google pour comprendre le code.
  - **Lire** : Parcourez la documentation attentivement.
  - **Expérimenter** : Testez des cas limites pour voir comment le code se comporte.

</div>

---
<div class="small-text">

## Préparation
1. Installer Python via Anaconda
   1. Outil de distrubtion pour installer Python avec des librairies orientées DataScience
2. Créer un compte sur [GitHub](https://github.com/) 
   1. vous pouvez ensuite créer un [compte étudiant](https://education.github.com/pack) (Facultatif)
   2. Cela vous permet d'accéder à divers outils de <u>manière gratuite</u>
   3. [Copilot](https://github.com/features/copilot) pour avoir accès à chatGPT dans votre base de code (gratuit pour les étudiants)
   4. Heroku pour héberger des applications data gratuitement
   5. [Codespaces](https://github.com/features/codespaces): VsCode sur le cloud (peut-être utile pour collaborer)
</div>

---
<div class="small-text">

## VsCode vs Jetbrains vs ...
- Environnement de développement (IDE)
  - Les gouts et les couleurs ...
- [Vscode](https://code.visualstudio.com/) / [Vscodium](https://vscodium.com/)
  - Gratuit et marche avec la plupart des languages de programmation (python, HTML/CSS/Javasript etc.)
- [Jetbrains Pycharm](https://www.jetbrains.com/pycharm/) 
  - Gratuit uniquement pour les étudiants (sinon cher!)
  - Très complet et robuste pour les notebooks notamment
  - Il existe un logiciel pour chaque langage (par ex. DataGrip pour SQLL)
  
</div>

---
<div class="small-text">

## Cours
Je vous propose de vous servir des cours d'intro Python de Delphine Bernhard enseignante à l'université de Strasbourg
- Pour ce faire, il est possible d'aller sur Gitlab:
  -  [Partie 1](https://git.unistra.fr/dbernhard/pythonm1s1.git)
  -  [Partie 2](https://git.unistra.fr/dbernhard/pythonm1s2.git)
- Sinon, vous pouvez cloner les cours vers votre machine avec GIT pour lancer les notebooks: 

```bash
# Partie 1
git clone https://git.unistra.fr/dbernhard/pythonm1s1.git
# Partie 2
git clone https://git.unistra.fr/dbernhard/pythonm1s2.git
```  
</div>
---

## Notion à (re)voir:
1. Partie 1
   - `6.Fichier`
   - `7.Opérations sur String`
   - `8.Regex`
2. Partie 2
   - `1.Structures Données`
   - `2.Fonctions`
   - `4.Programmation Orientée Object`

---

## Discord

Pour poser vos questions ou me montrer du code:  
[Lien vers le server](https://discord.gg/QAqWxAPN)
---


## Data
1. **Datasets**
2. **API**
   - (FR) application programming interface
   - (EN) Interface de programmation
3. **Scraping**

---
## Datasets
- Le travail de collecte / nettoyage / regroupement des données a déjà été effectué.
- Vous pouvez vous servir de jeux de données déjà existant en <u>complément</u> mais ça ne sera pas suffisant pour le projet 
---
## Exemple de datasets

<div style="font-size:50%;">

| **Plateforme**                                    | **Site Web**                                                     | **Focus**                                         |
|---------------------------------------------------|------------------------------------------------------------------|---------------------------------------------------|
| Kaggle                                            | [kaggle.com/datasets](https://www.kaggle.com/datasets)           | Science des données, Machine Learning             |
| Gouvernement des États-Unis (Data.gov)            | [data.gov](https://www.data.gov/)                                | Données gouvernementales US              |
| Portail Open Data de l'Union Européenne           | [data.europa.eu](https://data.europa.eu/euodp/fr/data/)          | Données des institutions de l'UE    |
| Organisation Mondiale de la Santé (OMS)           | [who.int/data](https://www.who.int/data)                         | Données de santé                         |
| Banque Mondiale                                   | [data.worldbank.org](https://data.worldbank.org/)                | Données sur le développement              |
| Gouvernement Français (data.gouv.fr)              | [data.gouv.fr](https://www.data.gouv.fr/)                        | Données gouvernementales françaises      |
</div>

---
## Qu'est-ce qu'une API ?

- **API** (Interface de Programmation d'Applications) permet à deux systèmes de communiquer entre eux.
- Les **requêtes GET** sont utilisées pour **obtenir des données** d'un serveur.
- Les **requêtes POST** sont utilisées pour **envoyer des données** à un serveur.

---
<div style="font-size:50%;">

- **API de Twitter** : Accès en temps réel aux tweets, mentions, et autres activités sociales.
  - URL : [https://developer.twitter.com/](https://developer.twitter.com/)

- **API de l'OpenWeatherMap** : Données météorologiques en temps réel pour n'importe quel lieu dans le monde.
  - URL : [https://openweathermap.org/api](https://openweathermap.org/api)

- **API de NewsAPI** : Accès aux articles de presse en temps réel de diverses sources d'actualité.
  - URL : [https://newsapi.org/](https://newsapi.org/)
  
- **API de CoinGecko** : Données sur les prix des cryptomonnaies, informations de marché, et plus.
  - URL : [https://www.coingecko.com/fr/api](https://www.coingecko.com/fr/api)

- **API Publiques** : Une liste exhaustive d'API publiques pour différents usages.
  - URL : [https://github.com/public-apis/public-apis](https://github.com/public-apis/public-apis)

</div>
---

<!-- Slide 1 -->
## Qu'est-ce que le Web Scraping ?

- **Web Scraping** : Technique pour extraire des données de sites web.
- **Méthodes courantes** : 
  - **Parsing HTML** : Analyser le contenu HTML pour extraire des informations.
  - **APIs** : Utiliser les interfaces de programmation pour obtenir des données structurées.

---

<!-- Slide 2 -->
## Introduction à Beautiful Soup

- **Beautiful Soup** : Bibliothèque Python pour extraire des données HTML/XML.
- **Fonctionnalités** :
  - **Parsing HTML/XML** : Transforme le contenu en un arbre d'éléments.
  - **Navigation dans le DOM** : Accès facile aux balises et aux attributs.
- **Installation** :
  ```bash
  pip install beautifulsoup4
  ```

---
<div style="font-size:70%;">

<!-- Slide 3 -->
## Utilisation de BeautifulSoup4 (bs4)

- **Importation** :
```python
from bs4 import BeautifulSoup
```
- **Exemple de Code** :
```python
html_doc = "<html><head><title>Page Title</title></head><body><p>Some text.</p></body></html>"
soup = BeautifulSoup(html_doc, 'html.parser')
print(soup.title.string)  # Affiche "Page Title"
```
- **Méthodes Courantes** :
  - `soup.find()` : Trouver la première occurrence d'une balise.
  - `soup.find_all()` : Trouver toutes les occurrences d'une balise.

</div>
---
<div style="font-size:70%;">
<!-- Slide 4 -->

## Sites Dynamiques

- **Sites Dynamiques** :
  - Utilisent JavaScript pour charger des données après le chargement initial de la page.
  - Beautiful Soup ne peut pas gérer le JavaScript dynamique, il extrait uniquement le HTML statique.

- **Limites** :
  - Ne peut pas interagir avec les éléments dynamiques ou les sites qui nécessitent une interaction utilisateur (comme les formulaires).
</div>
---

<div style="font-size:70%;">

<!-- Slide 5 -->
## Introduction à Selenium

- **Selenium** : Permet de générer et d'interagir directement avec des pages web dans un navigateur.
- **Fonctionnalités** :
  - **Interactions** : Simule les clics, les défilements, et les saisies dans les formulaires.
  - **Exécution de JavaScript** : Permet d'interagir avec le contenu dynamique généré par JavaScript.
- **Installation** :
  ```bash
  pip install selenium
  ```
- **Exemple de Code** :
  ```python
  from selenium import webdriver
  driver = webdriver.Chrome()
  driver.get("https://example.com")
  print(driver.title)  # Affiche le titre de la page
  driver.quit()
  ```
</div>
---
<div style="font-size:70%;">

## Exercise

- Récupérer les données de ce site: [https://books.toscrape.com](https://books.toscrape.com)
- 1000 lives, on souhaite un tableau (excel ou autre) avec le titre, le nombre d'étoiles, le prix, la quantitié, le genre, la description etc...
- Avec [requests](https://requests.readthedocs.io/en/latest/) (pour récupérer le contenu) et [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- Bouton droit sur la page Web puis "Voir la page source" pour voir tout le code HTML
- Bouton droit puis "Inspecter" pour regarder un élément en particulier
- [Explication sympa](https://jhroy.ca/uqam/edm5240/BeautifulSoup-DocAbregee.pdf), sinon Google ou ChatGPT...
</div>

---
## Ressources
- Ramalho L. Fluent python: Clear, concise, and effective programming.” O’Reilly Media, Inc.”; 2015 Jul 30.
- Mitchell R. Web scraping with Python: Collecting more data from themodern web. ” O’Reilly Media, Inc.”; 2018 Mar 21.
- Géron, A., 2019. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media.